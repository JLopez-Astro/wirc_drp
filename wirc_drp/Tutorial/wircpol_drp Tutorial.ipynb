{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIRC+POL Data Reduction Tutorial #\n",
    "Welcome to the WIRC+POL data reduction pipeline (DRP) tutorial. The notebook will give you a basic run \n",
    "through of how to reduce WIRC+POL data and give you some details about the setup of the pipeline. \n",
    "\n",
    "### Pipeline Description ###\n",
    "The pipeline has been designed so that once read-in, each data file will be held in an object called a *wirc_data* object. Each *wircpol_data* object will contain, the raw (or calibrated) 2D data itself, relevant information about the data and a number of functions that will calibrate and process the data. It will also contain a list of *wircpol_source* objects, where each *wircpol_source* will correspond to a source in the field. The source object will contain thumbnails of the spectral traces, as well as the extracted spectrum and polarized spectrum for each source.\n",
    "\n",
    "Note: The current implementation has been designed with WIRC+POL data in mind, but we hope to extent this to WIRC+Spec data soon. \n",
    "\n",
    "### Assumptions ###\n",
    "We assume that you have set an environment variable called \"WIRC_DRP\" that points to the base directory of the DRP and that it is in your python path. Beyond the standard python packages we also assume you have astropy installed. \n",
    "\n",
    "The pipeline also requires the installation of image registration tools found here:https://github.com/keflavich/image_registration\n",
    "To Install, clone the repository and run the setup.py from a terminal:\n",
    ">python setup.py install\n",
    "\n",
    "### The Tutorial ### \n",
    "This tutorial will give an example of reducing a raw WIRC+POL data image from start to finish, and will give you an idea of the implementation of the pipeline along the way. We'll note that many of the later data reduction steps (e.g. spectral extraction) are works in progress, and so the final data products should not yet be used for science. The purpose of this tutorial is more to demonstrate the features of the pipeline rather than to teach you how to fully calibrate your data. \n",
    "\n",
    "## Step 0 - Make your calibration files ##\n",
    "The very first step will be to create your own master darks and master flats. For the sake of this tutorial we well assume that you have done this already, but we provide somed example code commented-out below. Already-made master darks and flats have been provided in the tutorial directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (wirc_object.py, line 897)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/Users/mamillar/Dropbox (Personal)/Library/Python/wirc_drp/wirc_drp/wirc_object.py\"\u001b[0;36m, line \u001b[0;32m897\u001b[0m\n\u001b[0;31m    def extract_spectra(self):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Import the important things\n",
    "%matplotlib inline\n",
    "import wirc_drp.wirc_object as wo\n",
    "from wirc_drp.utils import calibration\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.io.ascii as asci\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a master dark #####\n",
    "First you will need a list of files that will go into the master dark. It can be created like this: \n",
    "\n",
    "__bash> ls dark*.fits > dark_list.dat__\n",
    "\n",
    "Then you read it in and create your mater dark by taking the median of all the files in the list. A hotpixel map will also be generated by default.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Get the file list \n",
    "#os.chdir('/hcig1-nas/wircpol/data/20170611')\n",
    "#dark_list_fn = \"dark_list.dat\" #The file name for your list of dark files\n",
    "#dark_list1s = (asci.read(dark_list_fn, format = 'fast_no_header'))['col1'] #Read in the list\n",
    "\n",
    "### Create the master dark and a bad pixel map.\n",
    "### This function creates a new fits file based on the last filename in your dark_list and appends \"_master_dark.fits\"\n",
    "### The hot pixel map will be the same, except with a \"_bp_map.fits\" suffix. \n",
    "#dark_name1s, bp_name = calibration.masterDark(dark_list1s) # The output of this function is a the filename \n",
    "                                                         # of the master dark and bad pixel maps\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a master flat #####\n",
    "First you will need a list of files that will go into the master flat. It can be created like this: \n",
    "\n",
    "__bash> ls flat*.fits > flat_list.dat__\n",
    "\n",
    "Then you read it in and create your mater flat by subtracting the master dark from each image, taking the median of all the files in the list and then normalize by either the median (default) or the mode, set by the *normalize* keyword. A bad pixel map will also be generated by default, which you can supplement with the hot pixel map output by creating the master dark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Get the file list \n",
    "# flat_list_fname = \"flat_list.dat\" #The file name for your list of flat files\n",
    "# flat_list = (a.read(flat_list_fname, format = 'fast_no_header'))['col1']\n",
    "\n",
    "### Create the master dark and a bad pixel map. You will need the filename \n",
    "### This function creates a new fits file based on the last filename in your flat list and appends \"_master_flat.fits\"\n",
    "\n",
    "# flat_name, bp_name = calibration.masterFlat(flat_list, dark_name1, hotp_map_fname = None) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Read in and calibrate your data ##\n",
    "Assuming that you now have a master dark and master flat file, we can now read in a wirc_data file and perform the calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First we'll set up all the directories and filenames: \n",
    "wircpol_dir = os.environ['WIRC_DRP'] # Your WIRCPOL_DRP directory (with a \"/\" at the end!)\n",
    "tutorial_dir = wircpol_dir + \"wirc_drp/Tutorial/\"\n",
    "\n",
    "raw_fn =tutorial_dir+\"wirc1586.fits\"\n",
    "flat_fn = tutorial_dir+\"wirc2012_master_flat.fits\"\n",
    "dark_fn = tutorial_dir+\"wirc0141_master_dark.fits\"\n",
    "bp_fn = tutorial_dir+\"wirc2012_bp_map.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we'll create the wirc_data object, passing in the filenames for the master dark, flat and bad pixel maps\n",
    "raw_data = wo.wirc_data(raw_filename=raw_fn, flat_fn = flat_fn, dark_fn = dark_fn, bp_fn = bp_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The wirc_data object holds the 2D data image in the property full_image. We can take a look at it now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(raw_data.full_image, vmin=0, vmax=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see (even in this zoomed out image) that there are a bunch of bad pixels. Let's run the calibration step. It will subtract the dark, divide by the flat, and interpolate over the bad pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data.calibrate(mask_bad_pixels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(raw_data.full_image, vmin=0, vmax=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few remaining artifacts in the image, but overall, not bad! \n",
    "\n",
    "We're now done with calibration and so we want to save our newly calibrated file. Up until now these steps can apply to both spec mode and pol mode data. However, the rest of the tutorial will just demonstrate how to reduce POL data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data.save_wirc_object(\"calibrated.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Extract the thumbnails of the spectral traces ##\n",
    "In this step we will give the wirc_object the location of the central mask hole, and it will create a source object. Each source object will contain cutout thumbnails of each spectral trace, and eventually spectra and polarized spectra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we'll create a new data object, mostly just to demonstrate how to read in an existing wirc_data object. \n",
    "calibrated_data = wo.wirc_data(wirc_object_filename=\"calibrated.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We'll now attempt to find sources in the image. \n",
    "calibrated_data.find_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source objects are kept in a python list called *source_list* and the number of sources are kept in a variable called *n_sources*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For the source let's now get the cutouts of the spectra. \n",
    "calibrated_data.source_list[0].get_cutouts(calibrated_data.full_image, calibrated_data.filter_name, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now let's take a look at them!\n",
    "calibrated_data.source_list[0].plot_cutouts(origin = 'lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We'll now manually add another source in the field with the instructions above: \n",
    "calibrated_data.source_list.append(wo.wircpol_source([1035,640],'slitless',calibrated_data.n_sources+1))\n",
    "calibrated_data.n_sources += 1\n",
    "calibrated_data.source_list[1].get_cutouts(calibrated_data.full_image, calibrated_data.filter_name, True)\n",
    "#The final argument being passed is a boolean that determines whether or not we compensate for hitting \n",
    "#the vertical bar of doom. Play with it to see the different results. How to properly compensate for this\n",
    "#is a work in progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calibrated_data.source_list[1].plot_cutouts(origin = 'lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Extract the spectra from each thumbnail ##\n",
    "In this step we will extract the specta from one of the source objects we found in Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here you can enable \"plot\" to see where the traces were \"found\"\n",
    "calibrated_data.source_list[0].extract_spectra(plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#And we'll plot the data!\n",
    "calibrated_data.source_list[0].plot_trace_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do a rough wavelength calibration. Currently it uses the edge of the filters to shift and scale the spectra. This will eventually need to be refined as we're not super happy with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now we'll do a rough wavelength calibration and plot the data again\n",
    "calibrated_data.source_list[0].rough_lambda_calibration(method=2) \n",
    "#Note method=1 is broken. \n",
    "\n",
    "#And we'll plot the data again. \n",
    "calibrated_data.source_list[0].plot_trace_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Calculate the polarized spectra ##\n",
    "We now combine the 4 spectra to calculate Stokes Q and U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calibrated_data.source_list[0].compute_polarization(cutmin=20, cutmax=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calibrated_data.source_list[0].plot_Q_and_U()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Save the wirc object ##\n",
    "We now save the new information and tables to a new file\n",
    "Note how it initiates the table columns even if the data hasn't been computed (for example, we haven't computed source_list[1] yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calibrated_data.save_wirc_object(\"calibrated2.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
